---
layout: about
title: about
permalink: /
subtitle:

profile:
  align: right
  image: wyc.png
  image_circular: false # crops the image to make it circular
  more_info: 

news: true # includes a list of news items
internship: true # includes a list of internship items
invited_talks: true # includes a list of invited talks items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I'm Yuancheng Wang (王远程), a PhD student at [the Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), SDS](https://sds.cuhk.edu.cn/en), supervised by Prof. [Zhizheng Wu](http://www.drwuz.com/). before that, I received the B.S. degree at CUHK-Shenzhen.
My research interests include **Multi-modal LLM, Generative AI for Speech and Audio, Post-Training, and Representation Learning**. I am currently a research scientist intern at Meta Superintelligence Labs, working on enhancing the speech capabilities of Llama models. Previously, I have also interned at Microsoft Research Asia (MSRA) and ByteDance.

I have developed several advanced TTS models, including NaturalSpeech 3 and MaskGCT, and I am one of the main contributors and leaders of the open-source Amphion [Amphion](https://github.com/open-mmlab/Amphion)[![GitHub stars](https://img.shields.io/github/stars/open-mmlab/Amphion)](https://github.com/open-mmlab/Amphion) toolkit. My work has been published at top international AI conferences such as NeurIPS, ICML, ICLR, ACL, IEEE SLT and IEEE TASLP.

**I am looking for a full-time position now, feel free to contact me if you are interested in my experience!**
