---
---

@misc{tadicodec,
  title={TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling},
  author={Wang, Yuancheng and Chen, Dekun and Zhang, Xueyao and Zhang, Junan and Li, Jiaqi and Wu, Zhizheng},
  abbr={Preprint},
  year={2025},
  arxiv={2508.16790},
  demo={https://tadicodec.github.io/},
  code={https://github.com/HeCheng0625/Diffusion-Speech-Tokenizer},
  huggingface={https://huggingface.co/amphion/TaDiCodec},
  selected={true},
  tldr={We introduce the Text-aware Diffusion Transformer Speech Codec with the token rate of 6.25 Hz for speech language modeling.}
}

@misc{intp,
  title={Advancing Zero-shot Text-to-Speech Intelligibility across Diverse Domains via Preference Alignment},
  author={Zhang*, Xueyao and Wang*, Yuancheng and Wang, Chaoren and Li, Ziniu and Chen, Zhuo and Wu, Zhizheng},
  abbr={ACL 2025},
  year={2025},
  arxiv={2505.04113},
  demo={https://intalign.github.io/},
  selected={true},
  tldr={We propose the INTP dataset and extend preference alignment to enhance the intelligibility and overall quality of TTS systems in challenging scenarios.}
}


@misc{wang2025metis,
  title={Metis: A Foundation Speech Generation Model with Masked Generative Pre-training},
  author={Wang, Yuancheng and Zheng, Jiachen and Zhang, Junan and Zhang, Xueyao and Liao, Huan and Wu, Zhizheng},
  abbr={Preprint},
  year={2025},
  arxiv={2502.03128},
  code={https://github.com/open-mmlab/Amphion/tree/main/models/tts/metis},
  huggingface={https://huggingface.co/amphion/metis},
  selected={true},
  tldr={We propose a foundation speech generation model with masked generative pre-training.}
}

@misc{wang2024maskgct,
  title={MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer},
  author={Wang, Yuancheng and Zhan, Haoyue and Liu, Liwei and Zeng, Ruihong and Guo, Haotian and Zheng, Jiachen and Zhang, Qiang and Zhang, Xueyao and Zhang, Shunsi and Wu, Zhizheng},
  abbr={ICLR 2025},
  year={2025},
  arxiv={2409.00750},
  code={https://github.com/open-mmlab/Amphion/blob/main/models/tts/maskgct},
  demo={https://maskgct.github.io},
  huggingface={https://huggingface.co/amphion/maskgct},
  selected={true},
  tldr={A fully non-autoregressive large-scale zero-shot TTS model eliminates the need for phone-level duration prediction.}
}

@misc{ju2024naturalspeech,
  title={Naturalspeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models},
  author={Ju*, Zeqian and Wang*, Yuancheng and Shen*, Kai and Tan*, Xu and Xin, Detai and Yang, Dongchao and Liu, Yanqing and Leng, Yichong and Song, Kaitao and Tang, Siliang and Wu, Zhizheng and Qin, Tao and Li, Xiang-Yang and Ye, Wei and Zhang, Shikun and Bian, Jiang and He, Lei and Li, Jinyu and Zhao, Sheng},
  year={2024},
  abbr={ICML 2024 Oral},
  arxiv={2403.03100},
  code={https://huggingface.co/amphion/naturalspeech3_facodec},
  demo={https://speechresearch.github.io/naturalspeech3},
  selected={true},
  tldr={A large-scale zero-shot TTS model achieves on-par quality with human recordings.}
}

@misc{ao2024sd,
  title={SD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words},
  author={Ao*, Junyi and Wang*, Yuancheng and Tian, Xiaohai and Chen, Dekun and Zhang, Jun and Lu, Lu and Wang, Yuxuan and Li, Haizhou and Wu, Zhizheng},
  year={2024},
  abbr={NeurIPS 2024},
  arxiv={2406.13340},
  huggingface={https://huggingface.co/datasets/amphion/SD-Eval},
  selected={true},
  tldr={We propose a benchmark dataset to evaluate spoken dialogue understanding and generation.}
}

@misc{wang2023audit,
  title={AUDIT: Audio Editing by following Instructions with Latent Diffusion Models},
  author={Wang, Yuancheng and Ju, Zeqian and Tan, Xu and He, Lei and Wu, Zhizheng and Bian, Jiang},
  year={2023},
  abbr={NeurIPS 2023},
  arxiv={2304.00830},
  code={https://github.com/HeCheng0625/AUDIT_v2},
  demo={https://audit-demo.github.io/},
  selected={true},
  tldr={The first audio editing model that can follow natural language instructions.}
}

@misc{zhang2024amphion,
  title={Amphion: an Open-Source Audio, Music, and Speech Generation Toolkit
},
  author={Zhang*, Xueyao and Xue*, Liumeng and Gu*, Yicheng and Wang*, Yuancheng and Li, Jiaqi and He, Haorui and Wang, Chaoren and Liu, Songting and Chen, Xi and Zhang, Junan and Tang, Tze Ying and Zou, Lexiao and Wang, Mingxuan and Han, Jun and Chen, Kai and Li, Haizhou and Wu, Zhizheng},
  year={2024},
  abbr={IEEE SLT 2024},
  arxiv={2312.09911},
  code={https://github.com/open-mmlab/Amphion},
  huggingface={https://huggingface.co/amphion},
  selected={true},
  tldr={We develop a unified toolkit for audio, music, and speech generation.}
}

@misc{he2024emilia,
  title={Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation},
  author={He, Haorui and Shang, Zengqiang and Wang, Chaoren and Li, Xuyuan and Gu, Yicheng and Hua, Hua and Liu, Liwei and Yang, Chen and Li, Jiaqi and Shi, Peiyang and Wang, Yuancheng and Chen, Kai and Zhang, Pengyuan and Wu, Zhizheng},
  year={2024},
  abbr={IEEE SLT 2024},
  arxiv={2407.05361},
  huggingface={https://huggingface.co/datasets/amphion/Emilia},
  selected={true},
  tldr={We collect a 10w hours in-the-wild speech dataset for speech generation.}
}

@misc{zhang2024foleycrafter,
  title={FoleyCrafter: Bring Silent Videos to Life with Lifelike and Synchronized Sounds},
  author={Zhang, Yiming and Gu, Yicheng and Zeng, Yanhong and Xing, Zhening and Wang, Yuancheng and Wu, Zhizheng and Chen, Kai},
  year={2024},
  abbr={Preprint},
  arxiv={2407.01494},
  code={https://github.com/open-mmlab/foleycrafter},
  demo={https://foleycrafter.github.io/},
  huggingface={https://huggingface.co/spaces/ymzhang319/FoleyCrafter}
}

@misc{huang2024debatts,
  title={Debatts: Zero-Shot Debating Text-to-Speech Synthesis},
  author={Huang, Yiqiao and Wang, Yuancheng and Li, Jiaqi and Guo, Haotian and He, Haorui and Zhang, Shunsi and Wu, Zhizheng},
  year={2024},
  abbr={Preprint},
  arxiv={2411.06540},
  code={https://github.com/open-mmlab/Amphion/tree/main/models/tts/debatts},
  huggingface={https://huggingface.co/datasets/amphion/Debatts-Data}
}

@misc{xin2024rall,
  title={RALL-E: Robust Audio Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis},
  author={Xin, Detai and Tan, Xu and Shen, Kai and Ju, Zeqian and Yang, Dongchao and Wang, Yuancheng and Takamichi, Shinnosuke and Saruwatari, Hiroshi and Liu, Shujie and Li, Jinyu and others},
  year={2024},
  abbr={Preprint},
  arxiv={2404.03204}
}

@misc{he2024noro,
  title={Noro: A Noise-Robust One-shot Voice Conversion System with Hidden Speaker Representation Capabilities},
  author={He, Haorui and Song, Yuchen and Wang, Yuancheng and Li, Haoyang and Zhang, Xueyao and Wang, Li and Huang, Gongping and Chng, Eng Siong and Wu, Zhizheng},
  year={2024},
  abbr={Preprint},
  arxiv={2411.19770},
  code={https://github.com/open-mmlab/Amphion/tree/main/models/vc/Noro}
}
